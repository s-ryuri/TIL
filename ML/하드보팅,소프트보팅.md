앙상블 학습은 보팅(voting), 배깅(Bagging) 부스팅(Boosting) 세 가지로 나눌 수 있다.

# 보팅과 배깅
보팅과 배깅은 여러 개의 분류기가 투표를 통해 최종 예측 결과를 결정하는 방식이다.  
이때 보팅은 서로 다른 알고리즘을 가진 분류기를 결합하는 방식이고  
배깅은 각각의 분류기가 모두 같은 유형의 알고리즘 기반이고 데이터 샘플링을 서로 다르게 가져가면서 학습을 수행해서 보팅을 수행한다.   
배깅의 대표적인 방식이 랜덤 포레스트이다.

![image](https://user-images.githubusercontent.com/66999675/130902189-9989a927-1494-428b-843c-1ae7f1de20df.png)  

보팅 방식을 그림으로 표현하면 위와 같다.  
모두 같은 데이터 셋을 사용하면서 서로 다른 분류기를 사용한다.

![image](https://user-images.githubusercontent.com/66999675/130902200-5d1d8856-0850-4207-88d3-5823bda981cb.png)  

배깅 방식을 그림으로 표현하면 위와 같다. 데이터 샘플링을 다르게 가져가되 서로 같은 모델을 사용해서 예측한다.

개별 분류기에 할당된 학습 데이터는 원본 학습 데이터를 샘플링해서 추출하는데   
이렇게 개별 Classifier에게 데이터를 샘플링해서 추출하는 방식을 Bootstrapping 분할 방식이라 한다.   
이때 부트스트래핑 방식은 데이터를 뽑을 때 중첩을 허용한다.

# 부스팅
부스팅은 여러 개의 분류기가 순차적으로 학습을 하되  
앞에서 학습한 분류기가 예측이 틀린 데이터에 대해서는 올바르게 예측할 수 있게   
다음 분류기에게는 가중치를 부여하면서 학습과 예측을 진행한다.  
계속해서 분류기에게 가중치를 부스팅 하면서 학습을 진행하기에 부스팅 방식으로 불린다.

# 하드 보팅

보팅 방법에는 하드 보팅과 소프트 보팅 방식이 있다.

하드 보팅은 예측한 결괏값들중 다수의 분류기가 결정한 예측값을 최종 보팅 결괏값으로 선정하는 방식이다.
다수결의 원칙이라고 생각하면 된다.

![image](https://user-images.githubusercontent.com/66999675/130902388-d604fd4a-987d-43e8-9acd-8bf5d3b95789.png)  


위의 그림은 하드 보팅을 표현한 것이다.   
분류기 1,2, 4는 1로 레이블 값을 예측하고 분류기 3만 2번 레이블로 예측한다.   
그럼 다수결의 원칙에 따라서 최종 예측은 1이 된다.  

# 소프트 보팅

소프트 보팅은 분류기들의 레이블 값 결정 확률을 모두 더하고 이를 평균해서   
이들 중 확률이 가장 높은 레이블 값을 최종 보팅 결괏값으로 선정한다.

![image](https://user-images.githubusercontent.com/66999675/130902443-61935a2f-bcf3-4b6d-a438-008dff1cdabf.png)  

소프트 보팅을 그림으로 표현한 것이다. 각 분류기의 레이블 값 예측 확률을 평균 내어 최종 결정을 한다.  
Class 1의 확률 평균은 (0.7 + 0.2 + 0.8 + 0.9) / 4 = 0.65  
Class 2의 확률 평균은 (0.3 + 0.8 + 0.2 + 0.1) / 4 = 0.35이기에 최종 예측은 Class 1이 된다.  
보통은 하드 보팅보다는 소프트 보팅이 예측 성능이 좋아서 더 많이 사용된다.  
